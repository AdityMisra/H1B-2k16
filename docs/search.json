[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "H1B 2K17 Analysis",
    "section": "",
    "text": "1 Introduction\nContext\nThe H-1B visa is a pathway for skilled foreign professionals to work in specialized fields in the United States. For international students and workers, it represents both an opportunity and a challenge due to its policy-driven nature. As discussions around potential changes to the program gain traction in 2024, understanding how industries, roles, and regions are impacted by such policies becomes increasingly important for navigating the uncertainties ahead.\nMotivation\nThe H-1B visa program has long been a cornerstone for skilled international professionals seeking opportunities in the USA. As international students pursuing higher education, we are interested in understanding the potential implications of policy shifts on our future career prospects. Our project examines H-1B visa trends during 2016, a pivotal year marked by a political transition as the Trump administration assumed office. We aim to analyze what changes occurred in industries, states, and job roles associated with H-1B visa sponsorship during that time. While we recognize that the socio-political and economic contexts of 2016 differ from those of today, this retrospective analysis helps us better understand the concerns surrounding the H-1B program in times of policy uncertainty. By studying data from 2016, a year that generated similar apprehensions among international professionals and students, we hope to gain insights that inform our decisions about navigating a potentially similar environment in 2025. This project seeks to provide a data-driven perspective, balancing anecdotal narratives with objective analysis.\nKey Questions\nIndustry Trends:\nWhich industries most successfully obtained H-1B visas in 2016, and how does this distribution compare to other years?\nState-Level Insights:\nWhich U.S. states had the highest number of approved H-1B petitions in 2016, and what factors contributed to their dominance?\nJob Role Distribution:\nWhat were the most common job roles for H-1B applicants in 2016, and how did these roles align with the prevailing demand for skills in the U.S. labor market?\nEmployer Characteristics:\nWho were the top employers sponsoring H-1B visas in 2016, and what trends can be observed about these companies’ size, industry, or location?\nApproval Rates and Salary Trends:\nWere there noticeable trends in the approval rates or salary levels for H-1B petitions in 2016, particularly about job roles, industries, or sponsoring states?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2  Data",
    "section": "",
    "text": "2.1 Description",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#description",
    "href": "data.html#description",
    "title": "2  Data",
    "section": "",
    "text": "2.1.1 Data Collection and Source\n\nCollected By: This data is collected by the Office of Foreign Labor Certification (OFLC) under the U.S. Department of Labor.\nHow Data is Collected:\n\nData is extracted from nonimmigrant and immigrant application tables in the OFLC’s case management systems.\nEmployers submit applications, and the information from these forms is entered into the system, including metadata generated during processing (e.g., submission and decision dates).\n\nSource Access:\n\nThis dataset is publicly available via the OFLC website and is distributed in Excel (.xlsx) format.\nDownload link for historical data: https://www.dol.gov/sites/dolgov/files/ETA/oflc/pdfs/H-1B_Disclosure_Data_FY17.xlsx\nDataset fields description: https://www.dol.gov/sites/dolgov/files/ETA/oflc/pdfs/H-1B_FY17_Record_Layout.pdf\n\n\n\n\n\n2.1.2 Data Format\n\nFile Type: Microsoft Excel (.xlsx).\nOrganization:\n\nThis dataset is cumulative for the fiscal year (October 1 – September 30).\nIt contains records with unique identifiers (e.g., OFLC case numbers).\n\nFields Included:\n\nEmployer-provided data (e.g., job title, worksite location, prevailing wage, and visa type).\nMetadata generated by the system (e.g., case status, received date, and determination date).\n\n\n\n\n\n2.1.3 Frequency of Updates\n\nThe data is updated quarterly and annually.\nThe H1-B 2017 dataset specifically covers cases for the fiscal year 2017 (October 1, 2016 – September 30, 2017) and will not receive further updates.\n\n\n\n\n2.1.4 Data Dimensions\n\nNumber of Records: Depends on the fiscal year’s total applications, in this case its 624651 rows.\nColumns/Attributes: 52 columns.\n\n\n\n\n2.1.5 Data Issues and Challenges\n\nKnown Issues:\n\nData Quality: Typographical errors and incomplete fields due to employer input errors or processing limitations.\nStandardization: Some fields might have inconsistent formats (e.g., job titles, worksite addresses or wages).\nOmissions: Records might exclude certain case details if the application is still under processing or if it includes open-ended text.\n\n\n\n\n\n2.1.6 Data Import Plan\n\nDownload: The data from the OFLC website will be downloaded using a R script as an xlsx file.\n\n\n\n\n2.1.7 Documentation of Sources\n\nPrimary Source: U.S. Department of Labor - Office of Foreign Labor Certification H-1B Disclosure Data\n\nWebsite: https://www.dol.gov/agencies/eta/foreign-labor/performance\nH-1B data file for 2017: https://www.dol.gov/sites/dolgov/files/ETA/oflc/pdfs/H-1B_Disclosure_Data_FY17.xlsx",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.2 Missing value analysis",
    "text": "2.2 Missing value analysis\n\n\nCode\n# Load required libraries\n#if (!require(\"readxl\")) install.packages(\"readxl\", dependencies = TRUE)\n#if (!require(\"dplyr\")) install.packages(\"dplyr\", dependencies = TRUE)\n\nlibrary(readxl)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(tidyverse)\n\n\n\n\nCode\n# The URL for the H1-B 2017 dataset\nurl &lt;- \"https://www.dol.gov/sites/dolgov/files/ETA/oflc/pdfs/H-1B_Disclosure_Data_FY17.xlsx\"\n\n# The destination of  file path for the Excel file\nfile_path &lt;- \"H-1B_Disclosure_Data_FY17.xlsx\"\n\n# Download the file\ndownload.file(url, destfile = file_path, mode = \"wb\")\n\nh1b_data &lt;- read_excel(file_path)\n\n#head(h1b_data)\n\nwrite.csv(h1b_data, file = \"H1B_2017_cleaned.csv\", row.names = FALSE)\n\n\n\n\nCode\n# Read the data\n#h1b_data &lt;- read_csv(\"H1B_2017_cleaned.csv\")\n\n# Calculate missing value counts\nmissing_values_summary &lt;- colSums(is.na(h1b_data))\n\nmissing_columns &lt;- missing_values_summary[missing_values_summary &gt; 0]\n\nmissing_table &lt;- data.frame(\n  Column = names(missing_columns),\n  MissingCount = as.numeric(missing_columns)\n)\n\nsorted_table &lt;- missing_table %&gt;%\n  arrange(desc(MissingCount))\n\nprint(sorted_table)\n\n\n                        Column MissingCount\n1   PUBLIC_DISCLOSURE_LOCATION       624650\n2           EMPLOYER_PHONE_EXT       587242\n3           ORIGINAL_CERT_DATE       574942\n4            EMPLOYER_PROVINCE       478203\n5        EMPLOYER_BUSINESS_DBA       424769\n6              LABOR_CON_AGREE       379675\n7         AGENT_ATTORNEY_STATE       288641\n8          AGENT_ATTORNEY_CITY       273306\n9               EMPLOYER_PHONE        96508\n10            EMPLOYER_COUNTRY        96507\n11 AGENT_REPRESENTING_EMPLOYER        96506\n12               PW_WAGE_LEVEL        96503\n13                 SUPPORT_H1B        43767\n14            WILLFUL_VIOLATOR        13745\n15               H1B_DEPENDENT        13742\n16             PW_SOURCE_OTHER         3331\n17              PW_UNIT_OF_PAY           46\n18                   PW_SOURCE           46\n19              PW_SOURCE_YEAR           45\n20         EMPLOYMENT_END_DATE           30\n21       EMPLOYMENT_START_DATE           29\n22              EMPLOYER_STATE           18\n23              WORKSITE_STATE            9\n24            WAGE_UNIT_OF_PAY            8\n25                  NAICS_CODE            7\n26        EMPLOYER_POSTAL_CODE            6\n27               EMPLOYER_NAME            5\n28            EMPLOYER_ADDRESS            5\n29               EMPLOYER_CITY            5\n30          FULL_TIME_POSITION            5\n31        WORKSITE_POSTAL_CODE            5\n32               WORKSITE_CITY            4\n33             WORKSITE_COUNTY            4\n34                   JOB_TITLE            2\n35                    SOC_CODE            2\n36                    SOC_NAME            2\n37             PREVAILING_WAGE            1\n38         WAGE_RATE_OF_PAY_TO            1\n\n\nThe above table shows the missing values in each column respectively. We can see that missing values in some of the rows is huge (some of them are nearly empty). For example, Public Discolsure location is completely empty. It is possible that these values are not mandatory while filling the H-1B application, therefore leading to lot of missing information.\n\n\nCode\n# Plotting the percentage of missing values per column, sorted by descending missing percentage\nmissing_summary &lt;- colSums(is.na(h1b_data)) / nrow(h1b_data) * 100\nmissing_df &lt;- data.frame(Column = names(missing_summary), MissingPercentage = missing_summary)\n\nggplot(missing_df, aes(x = reorder(Column, MissingPercentage), y = MissingPercentage)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  coord_flip() +\n  labs(\n    title = \"Percentage of Missing Values per Column\",\n    x = \"Columns\",\n    y = \"Missing Percentage (%)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThe above horizontal bar graph gives a relative view of missing values in all the columns of the dataset. Missing values can, of course, complicate the analysis; however, in our case, the columns with a high number of missing values are not critical to our primary objectives. The data in these columns—such as PUBLIC_DISCLOSURE_LOCATION, EMPLOYER_PHONE_EXT, and EMPLOYER_PROVINCE—serve as supporting information rather than core data required for analysis.\nFor example, columns like PUBLIC_DISCLOSURE_LOCATION only provides metadata about the file’s storage location, which is not directly related to analyzing H-1B visa trends or employer statistics. Similarly, fields such as EMPLOYER_PHONE_EXT and EMPLOYER_PROVINCE primarily address contact details, which are not relevant for our analysis.\n\n\nCode\nset.seed(42)\nsampled_data &lt;- h1b_data[sample(1:nrow(h1b_data), 5000), ]\n\nmissing_long &lt;- as.data.frame(is.na(sampled_data)) %&gt;%\n  pivot_longer(cols = everything(), names_to = \"Column\", values_to = \"IsMissing\")\n\nmissing_long &lt;- cbind(RowIndex = rep(1:nrow(sampled_data), times = ncol(sampled_data)), missing_long)\n\n# Plotting heatmap of missing data\nggplot(missing_long, aes(x = Column, y = RowIndex, fill = IsMissing)) +\n  geom_tile() +\n  scale_fill_manual(values = c(\"FALSE\" = \"white\", \"TRUE\" = \"red\"), name = \"Missing\") +\n  labs(title = \"Heatmap of Missing Data (Sampled Rows)\",\n       x = \"Columns\",\n       y = \"Row Index\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\nThe above missing value heatmap shows that missing data is concentrated only in certain columns. The rest of the columns have little to no missing data. This helps us streamline the data cleaning process.\n\n\nCode\n# Group missingness by CASE_STATUS and calculate the average missing count\ngrouped_missing &lt;- h1b_data %&gt;%\n  mutate(MissingCount = rowSums(is.na(.))) %&gt;%\n  group_by(CASE_STATUS) %&gt;%\n  summarise(AverageMissing = mean(MissingCount)) %&gt;%\n  arrange(desc(AverageMissing)) # Optional: Sort for better visualization\n\n# Plotting grouped missingness\nggplot(grouped_missing, aes(x = reorder(CASE_STATUS, -AverageMissing), y = AverageMissing)) +\n  geom_bar(stat = \"identity\", fill = \"orange\") +\n  labs(title = \"Average Missing Values by CASE STATUS\",\n       x = \"CASE STATUS\",\n       y = \"Average Missing Count\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nThis chart visualizes the average count of missing values for different categories of the column CASE_STATUS which represents the status of H-1B visa application.\nThe average missing values are similar across all statuses indicating no major variation in the amount of missing data among different application statuses. This implies that to handle the missing data, this graph shows that removing missing values wont introduce bias towards a specific case status.\n\n\nCode\nnumeric_data &lt;- h1b_data %&gt;%\n  select_if(is.numeric)\n\nstandardized_data &lt;- as.data.frame(scale(numeric_data))\n\nset.seed(42) \nsubset_data &lt;- standardized_data[sample(1:nrow(standardized_data), 1000), ]\n\nsubset_data &lt;- subset_data %&gt;%\n  mutate(RowIndex = 1:nrow(.)) %&gt;%\n  pivot_longer(cols = -RowIndex, names_to = \"Variable\", values_to = \"Value\")\n\nggplot(subset_data, aes(x = Variable, y = RowIndex, fill = Value)) +\n  geom_tile() +\n  scale_fill_gradient2(low = \"blue\", mid = \"white\", high = \"black\", midpoint = 0) +\n  labs(title = \"Heatmap of Standardized Variables (Subset of Rows)\",\n       x = \"Variable\",\n       y = \"Row Index\",\n       fill = \"Standardized Value\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\nThe heatmap displayed is a visualization of standardised values in the dataset for missing values analysis. No visible pattern was found on the plotting of this graph indicating that there is no unique relationship between missing values of the columns. Additionally we also observe a fading effect when we take large number of rows. This is due to data being more homogenous, causing the the standarised values to cluster closer to 0. Some of the columns are completely white, indicating high number of missing values in those columns.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#data-pre-processing",
    "href": "data.html#data-pre-processing",
    "title": "2  Data",
    "section": "2.3 Data Pre-processing",
    "text": "2.3 Data Pre-processing\nBased on our results above we have decided to remove following columns from our data-set as they are either not useful to us or have a lot of missing values.\nThe columns that we are dropping:\nEMPLOYER_BUSINESS_DBA, EMPLOYER_ADDRESS, EMPLOYER_PROVINCE, EMPLOYER_PHONE, EMPLOYER_PHONE_EXT, ORIGINAL_CERT_DATE, AGENT_REPRESENTING_EMPLOYER, AGENT_ATTORNEY_NAME, AGENT_ATTORNEY_CITY, AGENT_ATTORNEY_STATE, PUBLIC_DISCLOSURE_LOCATION, LABOR_CON_AGREE.\n\n\nCode\ncolumns_to_remove &lt;- c(\n  \"EMPLOYER_BUSINESS_DBA\", \n  \"EMPLOYER_ADDRESS\", \n  \"EMPLOYER_PROVINCE\", \n  \"EMPLOYER_PHONE\", \n  \"EMPLOYER_PHONE_EXT\",\n  \"ORIGINAL_CERT_DATE\",\n  \"AGENT_REPRESENTING_EMPLOYER\",\n  \"AGENT_ATTORNEY_NAME\", \n  \"AGENT_ATTORNEY_CITY\", \n  \"AGENT_ATTORNEY_STATE\", \n  \"PUBLIC_DISCLOSURE_LOCATION\", \n  \"LABOR_CON_AGREE\"\n)\n\n# Removing the specified columns\nh1b_data_cleaned &lt;- h1b_data |&gt; \n  select(-all_of(columns_to_remove))\n\nwrite.csv(h1b_data_cleaned, file = \"H1B_2017_cleaned.csv\", row.names = FALSE)\n\n#head(h1b_data_cleaned)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "results.html",
    "href": "results.html",
    "title": "3  Results",
    "section": "",
    "text": "Code\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(scales)\nlibrary(forcats)\nlibrary(RColorBrewer)\nlibrary(ggmosaic)\n# Load the dataset\ndata &lt;- read.csv(\"H1B_2017_cleaned.csv\")\n\n\n\n\nCode\n# Convert DECISION_DATE to date format\ndata$DECISION_DATE &lt;- as.Date(data$DECISION_DATE)\n\n# Define quarters\ndata$Quarter &lt;- cut(data$DECISION_DATE,\n  breaks = as.Date(c(\"2016-10-01\", \"2016-12-31\", \"2017-03-31\", \"2017-06-30\", \"2017-09-30\")),\n  labels = c(\"Q4 2016\", \"Q1 2017\", \"Q2 2017\", \"Q3 2017\"),\n  right = TRUE\n)\n\n# Filter data to include only the defined quarters\nfiltered_data &lt;- data %&gt;% filter(!is.na(Quarter))\n\n# Group and count case statuses by quarter\nstatus_counts &lt;- filtered_data %&gt;%\n  group_by(CASE_STATUS) %&gt;%\n  mutate(Total = n()) %&gt;%  # Calculate total count for each CASE_STATUS\n  ungroup() %&gt;%\n  group_by(Quarter, CASE_STATUS) %&gt;%\n  summarise(Count = n(), .groups = \"drop\")\n\n# Reorder CASE_STATUS by the total counts\nstatus_counts$CASE_STATUS &lt;- fct_rev(fct_reorder(status_counts$CASE_STATUS, status_counts$Count, .desc = TRUE))\n# Define custom colors for each CASE_STATUS\ncustom_colors &lt;- c(\n  \"DENIED\" = \"red\",\n  \"WITHDRAWN\" = \"blue\",\n  \"CERTIFIED-WITHDRAWN\" = \"#facc43\",\n  \"CERTIFIED\" = \"#299643\"\n)\n\n# Create the bar graph with custom colors\nggplot(status_counts, aes(x = Quarter, y = Count, fill = CASE_STATUS)) +\n  geom_bar(stat = \"identity\", position = \"stack\") +\n  scale_fill_manual(values = custom_colors) +  # Apply custom colors\n  labs(\n    title = \"H1B Case Status Distribution by Quarter (2016-2017)\",\n    x = \"Quarter\",\n    y = \"Number of Cases\",\n    fill = \"Case Status\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 0, hjust = 0.5)) +\n  scale_y_continuous(labels = comma)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# NAICS Code to Industry Name Mapping\nnaics_to_industry &lt;- c(\n  \"541211\" = \"Accountants\",\n  \"541330\" = \"Engineering Services\",\n  \"54151\" = \"Computer Systems\",\n  \"541511\" = \"Programming Services\",\n  \"541512\" = \"Computer Design\",\n  \"541519\" = \"Other Computer Related Services\",\n  \"5416\" = \"Technical Consulting\",\n  \"54161\" = \"Management Consulting\",\n  \"541611\" = \"Administrative Management\",\n  \"611310\" = \"Education\"\n)\n# Group and count case statuses by NAICS_CODE (Industry)\nindustry_counts &lt;- filtered_data %&gt;%\n  group_by(NAICS_CODE, CASE_STATUS) %&gt;%\n  summarise(Count = n(), .groups = \"drop\") %&gt;%\n  group_by(NAICS_CODE) %&gt;%\n  mutate(Total_Certified = sum(Count[CASE_STATUS == \"CERTIFIED\"])) %&gt;%\n  ungroup()\n\n# Select the top 10 industries by \"Certified\" applications\ntop_industries &lt;- industry_counts %&gt;%\n  filter(!is.na(NAICS_CODE)) %&gt;%  # Remove NA industries\n  arrange(desc(Total_Certified)) %&gt;%\n  distinct(NAICS_CODE, Total_Certified) %&gt;%\n  slice_head(n = 10)\n\n# Filter the data to include only the top 10 industries\ntop_industry_data &lt;- industry_counts %&gt;%\n  filter(NAICS_CODE %in% top_industries$NAICS_CODE)\n\n# Map the NAICS_CODE values to their corresponding Industry names\ntop_industry_data$Industry_Name &lt;- naics_to_industry[as.character(top_industry_data$NAICS_CODE)]\n\n# Print the unique pairs of NAICS_CODE and Industry_Name\nunique_industries &lt;- unique(top_industry_data[, c(\"NAICS_CODE\", \"Industry_Name\")])\n# Map NAICS_CODE values to corresponding Industry names\ntop_industry_data$Industry_Name &lt;- naics_to_industry[as.character(top_industry_data$NAICS_CODE)]\n\n# Create Cleveland dot plots faceted by CASE_STATUS\nggplot(top_industry_data, aes(\n  x = Count,\n  y = reorder(Industry_Name, Total_Certified)  # Order by Total Certified\n)) +\n  geom_point(aes(color = CASE_STATUS), size = 3) +\n  facet_wrap(~ CASE_STATUS, scales = \"free_x\") +  # Facet by case status\n  scale_color_manual(values = custom_colors) +  # Use custom colors for CASE_STATUS\n  labs(\n    title = \"Top 10 Industries by Applications (Faceted by Case Status)\",\n    x = \"Number of Applications\",\n    y = \"Industry\",\n    color = \"Case Status\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_text(size = 10),\n    axis.text.x = element_text(size = 8),\n    strip.text = element_text(size = 10, face = \"bold\"),\n    plot.title = element_text(size = 14, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\nfiltered_data &lt;- filtered_data %&gt;%\n  mutate(\n    Period = ifelse(\n      DECISION_DATE &lt; as.Date(\"2017-01-20\"), \n      \"Pre-Trump (Oct 2016 - Jan 2017)\", \n      \"Post-Trump (Jan 2017 - Sep 2017)\"\n    )\n  )\n# Load US state boundaries\nus_states &lt;- map_data(\"state\")\n# Prepare state abbreviations to full names mapping\nstate_abbrev &lt;- data.frame(\n  EMPLOYER_STATE = state.abb,\n  region = tolower(state.name)\n)\n# Aggregate data by EMPLOYER_STATE and Period\nstate_period_data &lt;- filtered_data %&gt;%\n  group_by(EMPLOYER_STATE, Period) %&gt;%\n  summarise(\n    Total_Applications = n(),\n    Certified_Applications = sum(CASE_STATUS == \"CERTIFIED\", na.rm = TRUE)\n  ) %&gt;%\n  ungroup()\n\n# Map state abbreviations to full names\nstate_period_data &lt;- state_period_data %&gt;%\n  left_join(state_abbrev, by = \"EMPLOYER_STATE\")\n\n# Join with map data\nmap_data &lt;- us_states %&gt;%\n  left_join(state_period_data, by = \"region\")\n# Plot pre-Trump map with \"YlGnBu\" color scheme\nggplot(filter(map_data, Period == \"Pre-Trump (Oct 2016 - Jan 2017)\"),\n       aes(x = long, y = lat, group = group, fill = Total_Applications)) +\n  geom_polygon(color = \"white\") +\n  scale_fill_distiller(\n    palette = \"YlGnBu\",\n    name = \"Total Applications\",\n    direction = 1,\n    na.value = \"grey50\"\n  ) +\n  labs(\n    title = \"H1B Applications by State (Pre-Trump Period)\",\n    subtitle = \"Oct 2016 - Jan 2017\",\n    x = \"\",\n    y = \"\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text = element_blank(),\n    axis.ticks = element_blank(),\n    panel.grid = element_blank()\n  )\n\n\n\n\n\n\n\n\n\nCode\n# Plot post-Trump map with the same color scheme\nggplot(filter(map_data, Period == \"Post-Trump (Jan 2017 - Sep 2017)\"),\n       aes(x = long, y = lat, group = group, fill = Total_Applications)) +\n  geom_polygon(color = \"white\") +\n  scale_fill_distiller(\n    palette = \"YlGnBu\",\n    name = \"Total Applications\",\n    direction = 1,\n    na.value = \"grey50\"\n  ) +\n  labs(\n    title = \"H1B Applications by State (Post-Trump Period)\",\n    subtitle = \"Jan 2017 - Sep 2017\",\n    x = \"\",\n    y = \"\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text = element_blank(),\n    axis.ticks = element_blank(),\n    panel.grid = element_blank()\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Load necessary librari\n\n# Filter out rows with missing or invalid wage data and exclude extreme outliers\nh1b_filtered &lt;- data %&gt;%\n  filter(!is.na(PREVAILING_WAGE) & !is.na(WAGE_RATE_OF_PAY_FROM) & \n         PREVAILING_WAGE &gt; 0 & WAGE_RATE_OF_PAY_FROM &gt; 0) %&gt;%\n  filter(PREVAILING_WAGE &lt; quantile(PREVAILING_WAGE, 0.99))  # Exclude top 1% of values\n\n# Create a scatter plot with log scale\nggplot(h1b_filtered, aes(x = PREVAILING_WAGE, y = WAGE_RATE_OF_PAY_FROM, color = CASE_STATUS)) +\n  geom_point(alpha = 0.6, size = 2) +  # Adjust transparency and point size\n  scale_x_continuous(labels = scales::comma) +  # Format x-axis with commas\n  scale_y_continuous(labels = scales::comma) +\n  labs(\n    title = \"Scatter Plot of Prevailing Wage vs. Wage Rate of Pay\",\n    x = \"Prevailing Wage (USD)\",\n    y = \"Wage Rate of Pay From (USD)\",\n    color = \"Case Status\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Load necessary libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lubridate)\n\n# Prepare the data\nh1b_faceted &lt;- data %&gt;%\n  mutate(\n    Quarter = case_when(\n      ymd(CASE_SUBMITTED) &gt;= ymd(\"2016-10-01\") & ymd(CASE_SUBMITTED) &lt;= ymd(\"2016-12-31\") ~ \"Oct-Dec 2016\",\n      ymd(CASE_SUBMITTED) &gt;= ymd(\"2017-01-01\") & ymd(CASE_SUBMITTED) &lt;= ymd(\"2017-03-31\") ~ \"Jan-Mar 2017\",\n      ymd(CASE_SUBMITTED) &gt;= ymd(\"2017-04-01\") & ymd(CASE_SUBMITTED) &lt;= ymd(\"2017-06-30\") ~ \"Apr-Jun 2017\",\n      ymd(CASE_SUBMITTED) &gt;= ymd(\"2017-07-01\") & ymd(CASE_SUBMITTED) &lt;= ymd(\"2017-09-30\") ~ \"Jul-Sep 2017\",\n      TRUE ~ \"Other\"\n    ),\n    EMPLOYMENT_TYPE = case_when(\n      NEW_EMPLOYMENT == 1 ~ \"New Employment\",\n      CONTINUED_EMPLOYMENT == 1 ~ \"Continued Employment\",\n      TRUE ~ \"Other\"\n    )\n  ) %&gt;%\n  filter(EMPLOYMENT_TYPE != \"Other\", Quarter != \"Other\")  # Keep only relevant rows\n\n# Summarize counts for each quarter and employment type\nfacet_data &lt;- h1b_faceted %&gt;%\n  group_by(Quarter, EMPLOYMENT_TYPE) %&gt;%\n  summarise(count = n(), .groups = \"drop\")\n\n# Calculate percentage of applications per quarter\nfacet_data &lt;- facet_data %&gt;%\n  group_by(Quarter) %&gt;%\n  mutate(percentage = count / sum(count) * 100) %&gt;%\n  ungroup()\n\n# Order the Quarter factor to ensure proper display in the plot\nfacet_data$Quarter &lt;- factor(facet_data$Quarter, levels = c(\"Oct-Dec 2016\", \"Jan-Mar 2017\", \"Apr-Jun 2017\", \"Jul-Sep 2017\"))\n\n# Create the faceted bar chart with percentages\nggplot(facet_data, aes(x = EMPLOYMENT_TYPE, y = percentage, fill = EMPLOYMENT_TYPE)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(\n    title = \"Percentage of New vs. Continued Employment by Quarter (Oct 2016 - Sep 2017)\",\n    x = \"Employment Type\",\n    y = \"Percentage of Applications\",\n    fill = \"Employment Type\"\n  ) +\n  scale_fill_manual(values = c(\"New Employment\" = \"steelblue\", \"Continued Employment\" = \"darkorange\")) +\n  theme_linedraw() +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    legend.position = \"none\",\n    axis.text.x = element_text(angle = 0, hjust = 0.5)  # Keep labels horizontal\n  ) +\n  facet_wrap(~ Quarter, ncol = 2, scales = 'free')\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter and map industries\nh1b_filtered &lt;- data %&gt;%\n  filter(!is.na(PREVAILING_WAGE) & PREVAILING_WAGE &gt; 0 & !is.na(NAICS_CODE)) %&gt;%\n  mutate(Industry = naics_to_industry[as.character(NAICS_CODE)]) %&gt;% # Map NAICS_CODE to Industry\n  filter(!is.na(Industry))  # Keep only rows with valid industry names\n\n# Calculate the 99th percentile of prevailing wages\nwage_99th_percentile &lt;- quantile(h1b_filtered$PREVAILING_WAGE, 0.99)\n\n# Filter out rows above the 99th percentile\nh1b_filtered &lt;- h1b_filtered %&gt;%\n  filter(PREVAILING_WAGE &lt;= wage_99th_percentile)\n\n# Create a box plot\nggplot(h1b_filtered, aes(x = Industry, y = PREVAILING_WAGE)) +\n  geom_boxplot(outlier.alpha = 0.5, fill = \"lightblue\") +\n  scale_y_log10(labels = scales::comma) +  # Log scale for wages to handle wide range\n  labs(\n    title = \"Distribution of Prevailing Wages Across Top Industries (99th Percentile)\",\n    x = \"Industry\",\n    y = \"Prevailing Wage (USD, Log Scale)\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    axis.text.x = element_text(angle = 45, hjust = 1)  # Rotate labels for clarity\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Prepare the data\nmosaic_data &lt;- filtered_data %&gt;%\n  filter(!is.na(PREVAILING_WAGE), !is.na(CASE_STATUS)) %&gt;%\n  mutate(\n    Wage_Range = cut(\n      PREVAILING_WAGE,\n      breaks = c(0, 50000, 100000, 150000, 200000, Inf),\n      labels = c(\"&lt;50k\", \"50k-100k\", \"100k-150k\", \"150k-200k\", \"&gt;200k\")\n    )\n  )\n\n# Create the mosaic plot\nggplot(mosaic_data) +\n  geom_mosaic(aes(x = product(Wage_Range), fill = CASE_STATUS, weight = 1)) +\n  labs(\n    title = \"Mosaic Plot of Wage Range and Case Status\",\n    x = \"Wage Range\",\n    y = \"Proportion\",\n    fill = \"Case Status\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Prepare data: Calculate average prevailing wage and denial rate by state\nscatter_data &lt;- filtered_data %&gt;%\n  filter(!is.na(PREVAILING_WAGE), !is.na(CASE_STATUS)) %&gt;%\n  group_by(EMPLOYER_STATE) %&gt;%\n  summarise(\n    Avg_Prevailing_Wage = mean(PREVAILING_WAGE, na.rm = TRUE),\n    Total_Applications = n(),\n    Denial_Rate = sum(CASE_STATUS == \"DENIED\") / Total_Applications\n  ) %&gt;%\n  filter(!is.na(Denial_Rate))\n\n# Create the scatter plot\nggplot(scatter_data, aes(x = Avg_Prevailing_Wage, y = Denial_Rate)) +\n  geom_point(\n    aes(size = Total_Applications, color = Denial_Rate),\n    shape = 21,             # Hollow circles\n    fill = \"white\",         # White fill inside the circles\n    alpha = 0.7,            # Transparency for overlapping points\n    stroke = 0.5            # Border thickness for better visibility\n  ) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"blue\") +  # Add regression line\n  scale_color_gradient(low = \"green\", high = \"red\") +\n  scale_size(range = c(2, 10)) +\n  labs(\n    title = \"Relationship Between Prevailing Wages and Denial Rate\",\n    x = \"Average Prevailing Wage\",\n    y = \"Denial Rate\",\n    size = \"Total Applications\",\n    color = \"Denial Rate\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"right\",\n    axis.text = element_text(size = 10),\n    plot.title = element_text(size = 14, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\nlibrary(ggalluvial)\nlibrary(dplyr)\n\n# Prepare data for the alluvial diagram\nalluvial_data &lt;- filtered_data %&gt;%\n  filter(!is.na(EMPLOYER_NAME), !is.na(EMPLOYER_STATE), !is.na(CASE_STATUS)) %&gt;%\n  group_by(EMPLOYER_NAME, EMPLOYER_STATE, CASE_STATUS) %&gt;%\n  summarise(Count = n(), .groups = \"drop\") %&gt;%\n  arrange(desc(Count))\n\n# Limit to top 10 employers for readability\ntop_employers &lt;- alluvial_data %&gt;%\n  group_by(EMPLOYER_NAME) %&gt;%\n  summarise(Total = sum(Count)) %&gt;%\n  arrange(desc(Total)) %&gt;%\n  slice_head(n = 10)\n\nfiltered_alluvial_data &lt;- alluvial_data %&gt;%\n  filter(EMPLOYER_NAME %in% top_employers$EMPLOYER_NAME)\n\n# Create the alluvial diagram\nggplot(filtered_alluvial_data,\n       aes(axis1 = EMPLOYER_NAME, axis2 = EMPLOYER_STATE, axis3 = CASE_STATUS, y = Count)) +\n  geom_alluvium(aes(fill = CASE_STATUS), alpha = 0.8) +\n  geom_stratum() +\n  geom_text(stat = \"stratum\", aes(label = after_stat(stratum)), size = 3, check_overlap = TRUE) +\n  scale_x_discrete(limits = c(\"Employers\", \"States\", \"Case Status\")) +\n  scale_fill_brewer(palette = \"Set3\") +  # Use a visually distinct color palette\n  labs(\n    title = \"Alluvial Diagram: Employer → State → Case Status\",\n    x = \"Stages\",\n    y = \"Number of Applications\",\n    fill = \"Case Status\"\n  ) +\n  theme_minimal() +\n  theme(\n    \n    plot.title = element_text(size = 14, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter data for certified applications and remove missing wages\ncertified_data &lt;- filtered_data %&gt;%\n  filter(CASE_STATUS == \"CERTIFIED\" & !is.na(PREVAILING_WAGE))\n\n# Create QQ plot for prevailing wages\nggplot(certified_data, aes(sample = PREVAILING_WAGE)) +\n  stat_qq() +\n  stat_qq_line(color = \"blue\", linetype = \"dashed\") +\n  labs(\n    title = \"QQ Plot of Prevailing Wages (Certified Applications)\",\n    x = \"Theoretical Quantiles\",\n    y = \"Sample Quantiles\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 14, face = \"bold\"),\n    axis.text = element_text(size = 10),\n    axis.title = element_text(size = 12)\n  )",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "d3graph.html",
    "href": "d3graph.html",
    "title": "4  Interactive graph",
    "section": "",
    "text": "Select State:\n\n\nAdd State\nRemove State\n\n\n\n\n\n\n\n\n\n\n  \n      \n         3  Results\n                \n  \n  \n      \n        5  Conclusion",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Interactive graph</span>"
    ]
  }
]